{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Spam Classifier",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kUTiT2E_M5H",
        "colab_type": "text"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU9l4_D1_M5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCUG0trn_M5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import sys\n",
        "import nltk\n",
        "from nltk.stem.porter import *\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoieloYD56U0",
        "colab_type": "code",
        "outputId": "41f1fd73-3ed0-4db5-9a2b-36c795de145a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Xtb_csJD_M5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/Shaastra Workshop Material/Text Analysis/spam.csv',encoding = \"ISO-8859-1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsWabRo-TKfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E8-W-3TTtda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.rename(columns={'v1':'target','v2':'text'},inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8u8w-AFv-3H",
        "colab_type": "code",
        "outputId": "23e2b890-6a45-406c-feaf-c9dc869a66db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  target                                               text\n",
              "0    ham  Go until jurong point, crazy.. Available only ...\n",
              "1    ham                      Ok lar... Joking wif u oni...\n",
              "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3    ham  U dun say so early hor... U c already then say...\n",
              "4    ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od7YmYLQ_M7k",
        "colab_type": "text"
      },
      "source": [
        "### Basic Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVMMYTwGxuNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = data.copy()\n",
        "\n",
        "train['text'] = train['text'].astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lOeA8PLt_M7z",
        "colab_type": "code",
        "outputId": "9f6ac926-625f-45ef-95b2-540191c3566d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "### Fill your code here\n",
        "\n",
        "## 1. Lowercasing\n",
        "train['text'] = train['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "\n",
        "## 2. Punctuation Removal\n",
        "train['text'] = train['text'].str.replace('[^\\w\\s]','')\n",
        "\n",
        "## 3. Stopwords Removal\n",
        "nltk.download('stopwords')\n",
        "## for removing the stopwords\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "train['text'] = train['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "train['text'].head()\n",
        "\"\"\" \n",
        "\n",
        "fill your code for all these operations\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\n\\nfill your code for all these operations\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1QGCz-0_M9F",
        "colab_type": "code",
        "outputId": "65fcad8b-c787-46cd-e18a-63d8ced55f5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "## lemmatization\n",
        "## write your code here\n",
        "\n",
        "from textblob import Word\n",
        "nltk.download('wordnet')\n",
        "train['text'] = train['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "train['text'].head()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    go jurong point crazy available bugis n great ...\n",
              "1                              ok lar joking wif u oni\n",
              "2    free entry 2 wkly comp win fa cup final tkts 2...\n",
              "3                  u dun say early hor u c already say\n",
              "4             nah dont think go usf life around though\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4Rng-D6_M9a",
        "colab_type": "text"
      },
      "source": [
        "### Target creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "v1h4taDp_M9f",
        "colab_type": "code",
        "outputId": "4cd068c9-f0d5-4f61-b22e-0e8f61d3b1b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "train['target'].unique()#.isna().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ham', 'spam'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJuHE_9K_M9p",
        "colab_type": "code",
        "outputId": "6ffa68c9-f9de-4b8e-dec8-458742879fc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "train['target'].replace(['ham','spam'],[0,1],inplace=True)\n",
        "train['target'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4825\n",
              "1     747\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE1ArY61XLzf",
        "colab_type": "code",
        "outputId": "4b857a40-461e-43a9-8384-758338277d23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>go jurong point crazy available bugis n great ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>u dun say early hor u c already say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>nah dont think go usf life around though</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>1</td>\n",
              "      <td>2nd time tried 2 contact u u å750 pound prize ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>0</td>\n",
              "      <td>ì_ b going esplanade fr home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>0</td>\n",
              "      <td>pity mood soany suggestion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>0</td>\n",
              "      <td>guy bitching acted like id interested buying s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>0</td>\n",
              "      <td>rofl true name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      target                                               text\n",
              "0          0  go jurong point crazy available bugis n great ...\n",
              "1          0                            ok lar joking wif u oni\n",
              "2          1  free entry 2 wkly comp win fa cup final tkts 2...\n",
              "3          0                u dun say early hor u c already say\n",
              "4          0           nah dont think go usf life around though\n",
              "...      ...                                                ...\n",
              "5567       1  2nd time tried 2 contact u u å750 pound prize ...\n",
              "5568       0                       ì_ b going esplanade fr home\n",
              "5569       0                         pity mood soany suggestion\n",
              "5570       0  guy bitching acted like id interested buying s...\n",
              "5571       0                                     rofl true name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GXIRkpoYhDQ",
        "colab_type": "text"
      },
      "source": [
        "### Basic Model on whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmAlQ-wlWHWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_valid,y_t,y_v = train_test_split(train['text'],train['target'],test_size=0.2,random_state=4353)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91U5c_i-W8-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(max_features=100, lowercase=True, analyzer='word',\n",
        " stop_words= 'english',ngram_range=(1,1))\n",
        "\n",
        "tfidf.fit(train['text'])\n",
        "\n",
        "x_t = tfidf.transform(x_train)\n",
        "x_v = tfidf.transform(x_valid)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATlrNFgMWbje",
        "colab_type": "code",
        "outputId": "30e37d0a-b281-49e1-e1d2-dd052fcacafe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "x_v.toarray().shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1115, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc5H47YRXc75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_training(clf, x_t, y_t, x_v=None , y_v=None ,task='binary:logistic'):\n",
        "    \n",
        "    clf.fit(x_t,y_t)\n",
        "    \n",
        "    print('training accuracy', clf.score(x_t,y_t))\n",
        "    \n",
        "    if task=='binary:logistic':\n",
        "      print('validation accuracy', clf.score(x_v,y_v))\n",
        "      print('validation f1_score',f1_score(clf.predict(x_v),y_v))\n",
        "      print('validation roc_auc score',roc_auc_score(y_v,clf.predict_proba(x_v)[::,-1]))\n",
        "      print('confusion matrix \\n',confusion_matrix(y_v, clf.predict(x_v)))\n",
        "    \n",
        "    if task=='reg:linear':\n",
        "        if x_v!=None:\n",
        "            print('validation r2_score', clf.score(x_v,y_v))\n",
        "            print('validation MSE',mean_squared_error(clf.predict(x_v),y_v))\n",
        "\n",
        "            \n",
        "    return clf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSSBgn-TW9Qd",
        "colab_type": "code",
        "outputId": "f2cd9d1a-32e4-405c-a054-56fbac5936b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "train['target'].mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.13406317300789664"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBOaguLBW-p5",
        "colab_type": "code",
        "outputId": "4b18af11-24c1-4cc8-b69f-a23d9b532159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import f1_score, classification_report, roc_auc_score, confusion_matrix, accuracy_score\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "lgr =  LogisticRegression(n_jobs=1)\n",
        "# model_training(lgr,x_t,y_t,x_v,y_v)\n",
        "\n",
        "xgb = XGBClassifier(n_estimators=500, max_depth=5,learning_rate=0.1,scale_pos_weight=1.4266790777602751)\n",
        "# xgb = XGBClassifier(n_estimators=500, max_depth=5,learning_rate=0.1,scale_pos_weight=1.6760372565622355)\n",
        "\n",
        "model_training(lgr,x_t,y_t,x_v,y_v)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training accuracy 0.9571460623737941\n",
            "validation accuracy 0.9560538116591928\n",
            "validation f1_score 0.7966804979253114\n",
            "validation roc_auc score 0.9571164021164021\n",
            "confusion matrix \n",
            " [[970  10]\n",
            " [ 39  96]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=1, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc9IGAr91Qm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training accuracy 0.974646623289208\n",
        "# validation accuracy 0.967713004484305\n",
        "# validation f1_score 0.859375\n",
        "# validation roc_auc score 0.9588548752834467\n",
        "# confusion matrix \n",
        "#  [[969  11]\n",
        "#  [ 25 110]]\n",
        "# XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "#               colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "#               learning_rate=0.1, max_delta_step=0, max_depth=5,\n",
        "#               min_child_weight=1, missing=None, n_estimators=500, n_jobs=1,\n",
        "#               nthread=None, objective='binary:logistic', random_state=0,\n",
        "#               reg_alpha=0, reg_lambda=1, scale_pos_weight=1.4266790777602751,\n",
        "#               seed=None, silent=None, subsample=1, verbosity=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGVi5Hkc_pnv",
        "colab_type": "text"
      },
      "source": [
        "### Training on pretrained word2vec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-joK9G7y_tqR",
        "colab_type": "code",
        "outputId": "468a21f0-a837-44ac-f444-fe936b9b8a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "import gensim\n",
        "import logging\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "wv = gensim.models.KeyedVectors.load_word2vec_format(\"/content/drive/My Drive/Shaastra Workshop Material/Text Analysis/GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
        "# above is only pretrained embeddings\n",
        "# wv = gensim.models.KeyedVectors.load_word2vec_format(\"tmp.txt\")\n",
        "\n",
        "wv.init_sims(replace=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l1uIbEc_yWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_averaging(wv, words):\n",
        "    all_words, mean = set(), []\n",
        "    \n",
        "    for word in words:\n",
        "        if isinstance(word, np.ndarray):\n",
        "            mean.append(word)\n",
        "        elif word in wv.vocab:\n",
        "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
        "            all_words.add(wv.vocab[word].index)\n",
        "\n",
        "    if not mean:\n",
        "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
        "        # FIXME: remove these examples in pre-processing\n",
        "        return np.zeros(wv.vector_size,)\n",
        "\n",
        "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
        "    return mean\n",
        "\n",
        "def  word_averaging_list(wv, text_list):\n",
        "    return np.vstack([word_averaging(wv, post) for post in text_list ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue-vtCsM3t5o",
        "colab_type": "code",
        "outputId": "41271292-7c7d-4fe6-974a-48555256167f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7ohGolk_24-",
        "colab_type": "code",
        "outputId": "b637d2ce-1197-4dee-b9f2-025b59f4b2cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "def w2v_tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text, language='english'):\n",
        "        for word in nltk.word_tokenize(sent, language='english'):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(word)\n",
        "    return tokens\n",
        "    \n",
        "train_w2v, test_w2v = train_test_split(train, test_size=0.2, random_state = 234)\n",
        "# x_t,x_v,y_t,y_v = train_test_split(train['tweet'],train['class'],test_size=0.2,random_state=234)\n",
        "\n",
        "test_tokenized = test_w2v.apply(lambda r: w2v_tokenize_text(r['text']), axis=1).values\n",
        "train_tokenized = train_w2v.apply(lambda r: w2v_tokenize_text(r['text']), axis=1).values\n",
        "\n",
        "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
        "X_test_word_average = word_averaging_list(wv,test_tokenized)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.wv.vectors_norm instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input ['erutupalam', 'thandiyachu']\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input ['645']\n",
            "WARNING:root:cannot compute similarity with no input ['doinghow']\n",
            "WARNING:root:cannot compute similarity with no input ['ringtoneking', '84484']\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input ['kkcongratulation']\n",
            "WARNING:root:cannot compute similarity with no input ['oktake', 'careumma']\n",
            "WARNING:root:cannot compute similarity with no input ['doinghow']\n",
            "WARNING:root:cannot compute similarity with no input ['lmaonice']\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input ['httptms', 'widelivecomindex', 'wmlid820554ad0a1705572711firsttrueåác', 'ringtoneåá']\n",
            "WARNING:root:cannot compute similarity with no input ['22', '146tf150p']\n",
            "WARNING:root:cannot compute similarity with no input ['neshanthtel']\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input ['staffsciencenusedusgphyhcmkteachingpc1323']\n",
            "WARNING:root:cannot compute similarity with no input ['alrite']\n",
            "WARNING:root:cannot compute similarity with no input ['ssnervous', 'ltgt']\n",
            "WARNING:root:cannot compute similarity with no input ['beerage']\n",
            "WARNING:root:cannot compute similarity with no input ['kall', 'bestcongrats']\n",
            "WARNING:root:cannot compute similarity with no input ['lunchyou', 'onlinewhy']\n",
            "WARNING:root:cannot compute similarity with no input ['nonenowhere', 'ikno', 'doesdiscountshitinnit']\n",
            "WARNING:root:cannot compute similarity with no input ['6times']\n",
            "WARNING:root:cannot compute similarity with no input ['kkyesterday', 'cbe']\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input ['gwr']\n",
            "WARNING:root:cannot compute similarity with no input ['latebut', 'kwish']\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-7boMQoeQW_",
        "colab_type": "code",
        "outputId": "3a624107-95fd-4ec3-ac65-83493de09f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "wv.similarity(w1='queen',w2='royal')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.56371856"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRNqiuZ6eQH1",
        "colab_type": "code",
        "outputId": "0dc3503b-be56-48a6-8bd5-d4e6decf3f99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "wv.similarity(w1='lion',w2='cub')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.40660018"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z3j686dADhf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import f1_score, classification_report, roc_auc_score, confusion_matrix, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiVo9hhL4UM7",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4FDiF73K7Sc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_training(clf, x_t, y_t, x_v=None , y_v=None ,task='binary:logistic'):\n",
        "    clf.fit(x_t,y_t)\n",
        "    print('training accuracy', clf.score(x_t,y_t))\n",
        "    \n",
        "    if task=='binary:logistic':\n",
        "      print('validation accuracy', clf.score(x_v,y_v))\n",
        "      print('validation f1_score',f1_score(clf.predict(x_v),y_v))\n",
        "      print('validation roc_auc score',roc_auc_score(y_v,clf.predict_proba(x_v)[::,-1]))\n",
        "      print('confusion matrix \\n',confusion_matrix(y_v, clf.predict(x_v)))\n",
        "    \n",
        "    if task=='reg:linear':\n",
        "      print('validation r2_score', clf.score(x_v,y_v))\n",
        "      print('validation MSE',mean_squared_error(clf.predict(x_v),y_v))\n",
        "\n",
        "            \n",
        "    return clf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II5GAU_0mS2L",
        "colab_type": "code",
        "outputId": "5b5221be-7d0f-4f07-be7a-1b76e885334a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "%%time\n",
        "xgb_w2v = XGBClassifier(n_estimators=500, max_depth=5,learning_rate=0.1,scale_pos_weight=1.4266790777602751)\n",
        "lgr_w2v = LogisticRegression(n_jobs=1)\n",
        "\n",
        "lgbm_w2v = LGBMClassifier(n_estimators=500)\n",
        "\n",
        "gbdt_w2v = GradientBoostingClassifier(n_estimators=500)\n",
        "\n",
        "model_training(xgb_w2v,X_train_word_average,train_w2v['target'],X_test_word_average,test_w2v['target'])\n",
        "\n",
        "# model_training(lgr_w2v,X_train_word_average,train_w2v['class'],X_test_word_average,test_w2v['class'])\n",
        "\n",
        "# model_training(lgbm_w2v,X_train_word_average,train_w2v['class'],X_test_word_average,test_w2v['class'])\n",
        "\n",
        "# model_training(gbdt_w2v,X_train_word_average,train_w2v['class'],X_test_word_average,test_w2v['class'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training accuracy 0.9993269015032533\n",
            "validation accuracy 0.9721973094170404\n",
            "validation f1_score 0.9034267912772586\n",
            "validation roc_auc score 0.9867553771434235\n",
            "confusion matrix \n",
            " [[939   5]\n",
            " [ 26 145]]\n",
            "CPU times: user 40.9 s, sys: 36.6 ms, total: 41 s\n",
            "Wall time: 41 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vEq8rRoTGpe",
        "colab_type": "code",
        "outputId": "b74b5e7e-71f7-4a8c-cbb2-f03064618c4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "tuned_pred = (xgb_w2v.predict_proba(X_test_word_average)[::,-1]>0.3).astype(int)\n",
        "confusion_matrix(test_w2v['target'],tuned_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[937,   7],\n",
              "       [ 24, 147]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f9dOMaSu6jb",
        "colab_type": "code",
        "outputId": "696f76b7-c400-48b6-df85-1c72153e7b2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f1_score(test_w2v['target'],tuned_pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9046153846153846"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frWc7zxJeMBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukagKnxShhJo",
        "colab_type": "text"
      },
      "source": [
        "### Word2Vec DOMAIN Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfUHo00fhjM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports needed and set up logging\n",
        "import gzip\n",
        "import gensim \n",
        "import logging\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FyKfzK_hm8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_input(data):\n",
        "    \"\"\"This method reads the input file which is in gzip format\"\"\"\n",
        "    i=0\n",
        "    for line in data['text']: \n",
        "      i+=1\n",
        "      if (i%10000==0):\n",
        "        logging.info (\"read {0} tweets\".format(i))\n",
        "      # do some pre-processing and return a list of words for each tweet, basically doing tokenizing\n",
        "      yield gensim.utils.simple_preprocess (line)\n",
        "\n",
        "# read the tokenized reviews into a list\n",
        "# each review item becomes a serries of words\n",
        "# so this becomes a list of lists\n",
        "documents = list(read_input(train))\n",
        "logging.info (\"Done reading data file\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRkv8_cThr_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "documents = []\n",
        "i=0\n",
        "for line in train['text']: \n",
        "    i+=1\n",
        "    if (i%1000==0):\n",
        "      logging.info (\"read {0} messages\".format(i))\n",
        "      # do some pre-processing and return a list of words for each tweet, basically doing tokenizing\n",
        "    # documents.append(gensim.utils.simple_preprocess(line))\n",
        "    documents.append(nltk.word_tokenize(line))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQRW7bPliNlU",
        "colab_type": "text"
      },
      "source": [
        "Training Time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1hroNBgiB0l",
        "colab_type": "code",
        "outputId": "320e20f8-ad93-4c41-9772-dc6c2af233a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "model = gensim.models.Word2Vec(documents, size=50, min_count=2, workers=5)\n",
        "model.train(documents,total_examples=len(documents),epochs=10)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
            "WARNING:gensim.models.base_any2vec:Effective 'alpha' higher than previous training cycles\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.55 s, sys: 29.9 ms, total: 2.58 s\n",
            "Wall time: 1.76 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er1sK2U8iP05",
        "colab_type": "code",
        "outputId": "11bcae53-b68d-4557-d360-96f2528b9bc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "w1 = \"discount\"\n",
        "model.wv.most_similar(positive=w1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('125gift', 0.9947423934936523),\n",
              " ('voucher', 0.9938306212425232),\n",
              " ('08000407165', 0.9904675483703613),\n",
              " ('operator', 0.9898449182510376),\n",
              " ('10p', 0.9889860153198242),\n",
              " ('40gb', 0.9866666793823242),\n",
              " ('ipod', 0.9851861000061035),\n",
              " ('entry', 0.9846733808517456),\n",
              " ('mobile', 0.984646737575531),\n",
              " ('rental', 0.9843345880508423)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja45F7nNi_oi",
        "colab_type": "code",
        "outputId": "1b632f89-c7af-4acd-c7bb-77e4fd03f3fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "model.wv.save_word2vec_format('tmp.txt', binary=False)\n",
        "## save the model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POtGkQKpjPhe",
        "colab_type": "code",
        "outputId": "45688f7d-77a6-4ae3-84e4-92167fe3b56d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "wv = gensim.models.KeyedVectors.load_word2vec_format('tmp.txt')\n",
        "wv.init_sims(replace=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ1soHPJmv8d",
        "colab_type": "code",
        "outputId": "6229fe5b-35c5-47d3-f4df-8da336d2215d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        }
      },
      "source": [
        "train_w2v, test_w2v = train_test_split(train, test_size=0.2, random_state = 234)\n",
        "# x_t,x_v,y_t,y_v = train_test_split(train['tweet'],train['class'],test_size=0.2,random_state=234)\n",
        "\n",
        "test_tokenized = test_w2v.apply(lambda r: w2v_tokenize_text(r['text']), axis=1).values\n",
        "train_tokenized = train_w2v.apply(lambda r: w2v_tokenize_text(r['text']), axis=1).values\n",
        "\n",
        "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
        "X_test_word_average = word_averaging_list(wv,test_tokenized)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.wv.vectors_norm instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input ['ultimately', 'tor', 'motive', 'tui', 'achieve', 'korli']\n",
            "WARNING:root:cannot compute similarity with no input ['erutupalam', 'thandiyachu']\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input ['hicts', 'employee']\n",
            "WARNING:root:cannot compute similarity with no input ['stalking']\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input ['645']\n",
            "WARNING:root:cannot compute similarity with no input ['ringtoneking', '84484']\n",
            "WARNING:root:cannot compute similarity with no input ['pocked']\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input ['kkcongratulation']\n",
            "WARNING:root:cannot compute similarity with no input ['lmaonice']\n",
            "WARNING:root:cannot compute similarity with no input ['ducking', 'chinchilla']\n",
            "WARNING:root:cannot compute similarity with no input ['rounderso', 'required']\n",
            "WARNING:root:cannot compute similarity with no input ['practising', 'curtsey']\n",
            "WARNING:root:cannot compute similarity with no input ['continent']\n",
            "WARNING:root:cannot compute similarity with no input ['keng', 'rocking', 'ash']\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input ['september']\n",
            "WARNING:root:cannot compute similarity with no input ['neshanthtel']\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input ['staffsciencenusedusgphyhcmkteachingpc1323']\n",
            "WARNING:root:cannot compute similarity with no input ['scratching']\n",
            "WARNING:root:cannot compute similarity with no input ['hank', 'lotsly']\n",
            "WARNING:root:cannot compute similarity with no input ['beerage']\n",
            "WARNING:root:cannot compute similarity with no input ['fps']\n",
            "WARNING:root:cannot compute similarity with no input ['kall', 'bestcongrats']\n",
            "WARNING:root:cannot compute similarity with no input ['stitch', 'trouser']\n",
            "WARNING:root:cannot compute similarity with no input ['lunchyou', 'onlinewhy']\n",
            "WARNING:root:cannot compute similarity with no input ['nonenowhere', 'ikno', 'doesdiscountshitinnit']\n",
            "WARNING:root:cannot compute similarity with no input ['6times']\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input ['gwr']\n",
            "WARNING:root:cannot compute similarity with no input ['latebut', 'kwish']\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UC3eqqaPm2-P",
        "colab_type": "code",
        "outputId": "adf83403-d3bc-46e0-a292-1f53af1eff94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "%%time\n",
        "xgb_w2v = XGBClassifier(n_estimators=500, max_depth=5,learning_rate=0.1,scale_pos_weight=1.4266790777602751)\n",
        "lgr_w2v = LogisticRegression(n_jobs=1)\n",
        "\n",
        "lgbm_w2v = LGBMClassifier(n_estimators=500)\n",
        "\n",
        "gbdt_w2v = GradientBoostingClassifier(n_estimators=500)\n",
        "\n",
        "model_training(xgb_w2v,X_train_word_average,train_w2v['target'],X_test_word_average,test_w2v['target'])\n",
        "\n",
        "# model_training(lgr_w2v,X_train_word_average,train_w2v['class'],X_test_word_average,test_w2v['class'])\n",
        "\n",
        "# model_training(lgbm_w2v,X_train_word_average,train_w2v['class'],X_test_word_average,test_w2v['class'])\n",
        "\n",
        "# model_training(gbdt_w2v,X_train_word_average,train_w2v['class'],X_test_word_average,test_w2v['class'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training accuracy 0.9997756338344178\n",
            "validation accuracy 0.9704035874439462\n",
            "validation f1_score 0.8984615384615385\n",
            "validation roc_auc score 0.9761373773416593\n",
            "confusion matrix \n",
            " [[936   8]\n",
            " [ 25 146]]\n",
            "CPU times: user 8.14 s, sys: 24 ms, total: 8.16 s\n",
            "Wall time: 8.18 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdPHSs5onWa_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrs0rMyPnn5-",
        "colab_type": "text"
      },
      "source": [
        "### Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md53oizSnp-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "sentences = documents\n",
        "# size option needs to be set to 300 to be the same as Google's pre-trained model\n",
        " \n",
        "word2vec_model = Word2Vec(size = 300, window=5,\n",
        "min_count = 1, workers = 10)\n",
        "\n",
        "word2vec_model.build_vocab(sentences)\n",
        " \n",
        "# assign the vectors to the vocabs that are in Google's pre-trained model and your sentences defined above.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-dxYs9MnvGJ",
        "colab_type": "code",
        "outputId": "2fee6eb9-a421-44a6-9a07-eee4651f4c30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "word2vec_model.intersect_word2vec_format('/content/drive/My Drive/Shaastra Workshop Material/Text Analysis/GoogleNews-vectors-negative300.bin.gz', lockf=1.0, binary=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShcAp0oDoQNK",
        "colab_type": "code",
        "outputId": "600f7601-406f-4b69-a8e1-88ec545b15ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# continue training with you own data\n",
        "word2vec_model.train(sentences, total_examples=len(sentences), epochs = 5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(242893, 262305)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "035N-J4WoYb3",
        "colab_type": "code",
        "outputId": "f0242417-fc9f-4d84-a67f-089b7e4eae0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "w1 = [\"sale\"]\n",
        "word2vec_model.wv.most_similar (positive=w1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('sell', 0.6767012476921082),\n",
              " ('purchase', 0.6712290048599243),\n",
              " ('selling', 0.6567376852035522),\n",
              " ('auction', 0.6562143564224243),\n",
              " ('sold', 0.6543912887573242),\n",
              " ('buying', 0.5567315816879272),\n",
              " ('price', 0.5454237461090088),\n",
              " ('buy', 0.5431312918663025),\n",
              " ('buyer', 0.5379477739334106),\n",
              " ('bought', 0.5367680191993713)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYMVuRHrpVj1",
        "colab_type": "code",
        "outputId": "991143bf-b5f6-4f5d-f640-2304bb2d001a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "word2vec_model.wv.save_word2vec_format('model_transfer_learning.txt', binary=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGiOeMVjptEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Training on this"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jDyZFLlp0-K",
        "colab_type": "code",
        "outputId": "63cf0304-adde-4342-f960-8e5b12c3e4c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "\n",
        "wv = gensim.models.KeyedVectors.load_word2vec_format('model_transfer_learning.txt')\n",
        "wv.init_sims(replace=True)\n",
        "\n",
        "train_w2v, test_w2v = train_test_split(train, test_size=0.2, random_state = 234)\n",
        "# x_t,x_v,y_t,y_v = train_test_split(train['tweet'],train['class'],test_size=0.2,random_state=234)\n",
        "\n",
        "test_tokenized = test_w2v.apply(lambda r: w2v_tokenize_text(r['text']), axis=1).values\n",
        "train_tokenized = train_w2v.apply(lambda r: w2v_tokenize_text(r['text']), axis=1).values\n",
        "\n",
        "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
        "X_test_word_average = word_averaging_list(wv,test_tokenized)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `syn0norm` (Attribute will be removed in 4.0.0, use self.wv.vectors_norm instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input []\n",
            "WARNING:root:cannot compute similarity with no input []\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7-9Fxadp-LD",
        "colab_type": "code",
        "outputId": "b8b4968f-e67e-4b59-daab-8d03d18a90a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "%%time\n",
        "xgb_w2v = XGBClassifier(n_estimators=500, max_depth=5,learning_rate=0.1,scale_pos_weight=1.4266790777602751)\n",
        "lgr_w2v = LogisticRegression(n_jobs=1)\n",
        "\n",
        "lgbm_w2v = LGBMClassifier(n_estimators=500)\n",
        "\n",
        "gbdt_w2v = GradientBoostingClassifier(n_estimators=500)\n",
        "\n",
        "model_training(xgb_w2v,X_train_word_average,train_w2v['target'],X_test_word_average,test_w2v['target'])\n",
        "\n",
        "# model_training(lgr_w2v,X_train_word_average,train_w2v['class'],X_test_word_average,test_w2v['class'])\n",
        "\n",
        "# model_training(lgbm_w2v,X_train_word_average,train_w2v['class'],X_test_word_average,test_w2v['class'])\n",
        "\n",
        "# model_training(gbdt_w2v,X_train_word_average,train_w2v['class'],X_test_word_average,test_w2v['class'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training accuracy 1.0\n",
            "validation accuracy 0.9766816143497757\n",
            "validation f1_score 0.9202453987730062\n",
            "validation roc_auc score 0.9848597482406583\n",
            "confusion matrix \n",
            " [[939   5]\n",
            " [ 21 150]]\n",
            "CPU times: user 31.5 s, sys: 36.2 ms, total: 31.5 s\n",
            "Wall time: 31.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JirTZaICqDVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### indeed an increase in F1-Score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9stWWKlqP0w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}